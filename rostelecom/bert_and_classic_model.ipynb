{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af801f3-c04b-448e-98aa-31e8f5d62f58",
   "metadata": {},
   "source": [
    "# 3. BERT + classic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d41c9-dbee-4ffc-bfe6-41d8e6ae4efc",
   "metadata": {},
   "source": [
    "Будем получать эмбеддинги от BERT, а дальше так же, как и с TF-IDF, в полученном признаковом простанстве строить классические модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60778752-119a-40d2-8165-e8b4b2e3e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7610e7b-fc35-401d-8f7c-635092abac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c5b16f-4152-4197-8a48-4928f92a9feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer1</th>\n",
       "      <th>score1</th>\n",
       "      <th>answer2</th>\n",
       "      <th>score2</th>\n",
       "      <th>answer3</th>\n",
       "      <th>score3</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>для анализа массивов данных необходимых в работе</td>\n",
       "      <td>2.0</td>\n",
       "      <td>для анализа массивов данных необходимых в работе</td>\n",
       "      <td>2.0</td>\n",
       "      <td>стараюсь всегда брать задачи, выполнение котор...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>Буду использовать полученные знания в работе д...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Автоматизирую процесс сбора данных и дальнейше...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Задача по анализу кода и содержанию пакетов - ...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>хочу стать топовым программистом во всём мире ...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>изучаю программирование</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            answer1  score1  \\\n",
       "0  train_0   для анализа массивов данных необходимых в работе     2.0   \n",
       "1  train_1  Буду использовать полученные знания в работе д...     2.0   \n",
       "2  train_2  хочу стать топовым программистом во всём мире ...     1.5   \n",
       "\n",
       "                                             answer2  score2  \\\n",
       "0   для анализа массивов данных необходимых в работе     2.0   \n",
       "1  Автоматизирую процесс сбора данных и дальнейше...     2.0   \n",
       "2                            изучаю программирование     1.5   \n",
       "\n",
       "                                             answer3  score3  result  \n",
       "0  стараюсь всегда брать задачи, выполнение котор...     2.0     6.0  \n",
       "1  Задача по анализу кода и содержанию пакетов - ...     1.5     5.5  \n",
       "2                                                  -     0.0     3.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc2d6cb-c96b-48de-bbaf-1e8fbdf7f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75be040-d776-47ca-93fe-a10075eb1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "!set HF_HUB_DISABLE_SYMLINKS_WARNING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3403f1fc-b3a4-4456-9ee2-fbcba7e47c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711bb8fb-d65b-43ba-85f0-553d54d36799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
    "model = AutoModel.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3be8119-d517-4a59-aa19-f362b9c81f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def get_best_threshold(model, X_train, y_train):\n",
    "    \"\"\"Ищет лучший порог отсечения, который максимизирует метрику f1_macro с использованием кросс-валидации\"\"\"\n",
    "    # Получаем вероятности предсказаний с помощью кросс-валидации\n",
    "    y_probs = cross_val_predict(model, X_train, y_train, cv=5, method='predict_proba')[:, 1]\n",
    "\n",
    "    thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "    f1_scores = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_probs >= threshold).astype(int)\n",
    "        f1 = f1_score(y_train, y_pred, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    optimal_f1 = max(f1_scores)\n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a593621a-dbcc-4d4d-af8c-164c9ca0a3fc",
   "metadata": {},
   "source": [
    "## 3.1. BERT + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ea9e32-26bd-4b18-a132-d962a5816600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec1666f-0960-4f0e-b45c-f24de87112cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "answer1    0\n",
       "score1     0\n",
       "answer2    1\n",
       "score2     0\n",
       "answer3    0\n",
       "score3     0\n",
       "result     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8c9d9-06a3-4cc1-875f-05234c62fd8e",
   "metadata": {},
   "source": [
    "Необходимо заполнить пропуски, так как BERT не сможет нормально работать с ними:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efac7129-dc43-4279-9c88-116dea11235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe159e7-f63e-4b80-b326-43567c5be136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a1f16d9-c7fe-48fc-922b-a78d98b8d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(sentences: list[str]):\n",
    "    \"\"\"Создает BERT-эмбеддинги для каждого текстового ответа\"\"\"\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=50, return_tensors='pt')\n",
    "    \n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8bff2-ad73-46c3-a385-b3d7979579d6",
   "metadata": {},
   "source": [
    "### 3.1.1. Пробная модель для первого вопроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e5c9041-f1c3-489f-a492-882d0cfd6e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer1</th>\n",
       "      <th>score1</th>\n",
       "      <th>answer2</th>\n",
       "      <th>score2</th>\n",
       "      <th>answer3</th>\n",
       "      <th>score3</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>для анализа массивов данных необходимых в работе</td>\n",
       "      <td>2.0</td>\n",
       "      <td>для анализа массивов данных необходимых в работе</td>\n",
       "      <td>2.0</td>\n",
       "      <td>стараюсь всегда брать задачи, выполнение котор...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           answer1  score1  \\\n",
       "0  train_0  для анализа массивов данных необходимых в работе     2.0   \n",
       "\n",
       "                                            answer2  score2  \\\n",
       "0  для анализа массивов данных необходимых в работе     2.0   \n",
       "\n",
       "                                             answer3  score3  result  \n",
       "0  стараюсь всегда брать задачи, выполнение котор...     2.0     6.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1935cbab-63c6-46c9-a459-54c027b368e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[['answer1']].copy(), df['score1'].copy()\n",
    "y = (y > 1.5).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e02f2ea-0c7b-4681-95f6-10fabf96f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_train = get_bert_embeddings(X_train['answer1'].tolist())\n",
    "sentence_embeddings_test = get_bert_embeddings(X_test['answer1'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b95d2278-b93a-4c12-8761-69c908b89075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.85       286\n",
      "           1       0.76      0.67      0.71       169\n",
      "\n",
      "    accuracy                           0.80       455\n",
      "   macro avg       0.79      0.77      0.78       455\n",
      "weighted avg       0.80      0.80      0.80       455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.69       123\n",
      "           1       0.48      0.51      0.49        73\n",
      "\n",
      "    accuracy                           0.61       196\n",
      "   macro avg       0.59      0.59      0.59       196\n",
      "weighted avg       0.62      0.61      0.61       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(sentence_embeddings_train, y_train)\n",
    "\n",
    "y_train_pred = knn.predict(sentence_embeddings_train)\n",
    "y_test_pred = knn.predict(sentence_embeddings_test)\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df6d7fc4-1f47-4e39-a07e-0c07e7f2ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import logging\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR) # отключаем стандартный вывод optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e6485e-73f0-44ea-bc13-04363cbeeab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: score = 0.684626103722526\n",
      "Trial 2: score = 0.639916789764689\n",
      "Trial 3: score = 0.6617942140159512\n",
      "Trial 4: score = 0.6500021286851122\n",
      "Trial 5: score = 0.6852113713817654\n",
      "Trial 6: score = 0.6605864073475145\n",
      "Trial 7: score = 0.6485623925908268\n",
      "Trial 8: score = 0.6765115760222987\n",
      "Trial 9: score = 0.6765672781051253\n",
      "Trial 10: score = 0.6765115760222987\n",
      "Trial 11: score = 0.6834933642395139\n",
      "Trial 12: score = 0.6904910810307511\n",
      "Trial 13: score = 0.6929523447947359\n",
      "Trial 14: score = 0.6947397383096601\n",
      "Trial 15: score = 0.6730512125213639\n",
      "Trial 16: score = 0.6713165077374927\n",
      "Trial 17: score = 0.6864878979323246\n",
      "Trial 18: score = 0.6713165077374927\n",
      "Trial 19: score = 0.6679041901437446\n",
      "Trial 20: score = 0.6475135425619651\n",
      "Trial 21: score = 0.666002130174009\n",
      "Trial 22: score = 0.6929523447947359\n",
      "Trial 23: score = 0.6929523447947359\n",
      "Trial 24: score = 0.6827070501364\n",
      "Trial 25: score = 0.6827070501364\n",
      "Trial 26: score = 0.6929523447947359\n",
      "Trial 27: score = 0.6781892070776167\n",
      "Trial 28: score = 0.682525002684992\n",
      "Trial 29: score = 0.6614497222143254\n",
      "Trial 30: score = 0.684626103722526\n",
      "Trial 31: score = 0.6738455719724926\n",
      "Trial 32: score = 0.6852113713817654\n",
      "Trial 33: score = 0.6929523447947359\n",
      "Trial 34: score = 0.6786650574392814\n",
      "Trial 35: score = 0.6916139437136348\n",
      "Trial 36: score = 0.6895955892394381\n",
      "Trial 37: score = 0.6639457300939448\n",
      "Trial 38: score = 0.6786860450077361\n",
      "Trial 39: score = 0.6765765244497868\n",
      "Trial 40: score = 0.666175894242005\n",
      "Trial 41: score = 0.674511479970232\n",
      "Trial 42: score = 0.6929523447947359\n",
      "Trial 43: score = 0.6929523447947359\n",
      "Trial 44: score = 0.6932016211341822\n",
      "Trial 45: score = 0.6885454602923601\n",
      "Trial 46: score = 0.6904910810307511\n",
      "Trial 47: score = 0.6916139437136348\n",
      "Trial 48: score = 0.6781892070776167\n",
      "Trial 49: score = 0.6864878979323246\n",
      "Trial 50: score = 0.6932016211341822\n",
      "Trial 51: score = 0.6767085087424425\n",
      "Trial 52: score = 0.6932016211341822\n",
      "Trial 53: score = 0.6932016211341822\n",
      "Trial 54: score = 0.6932016211341822\n",
      "Trial 55: score = 0.6932016211341822\n",
      "Trial 56: score = 0.684626103722526\n",
      "Trial 57: score = 0.6827070501364\n",
      "Trial 58: score = 0.6953713561774226\n",
      "Trial 59: score = 0.6738444227705085\n",
      "Trial 60: score = 0.6953713561774226\n",
      "Trial 61: score = 0.6953713561774226\n",
      "Trial 62: score = 0.6947397383096601\n",
      "Trial 63: score = 0.666002130174009\n",
      "Trial 64: score = 0.682525002684992\n",
      "Trial 65: score = 0.6947397383096601\n",
      "Trial 66: score = 0.6730512125213639\n",
      "Trial 67: score = 0.6820211808691401\n",
      "Trial 68: score = 0.6738455719724926\n",
      "Trial 69: score = 0.6895955892394381\n",
      "Trial 70: score = 0.6947397383096601\n",
      "Trial 71: score = 0.6688299935424245\n",
      "Trial 72: score = 0.6758573010257425\n",
      "Trial 73: score = 0.6953713561774226\n",
      "Trial 74: score = 0.6953713561774226\n",
      "Trial 75: score = 0.6895955892394381\n",
      "Trial 76: score = 0.6834933642395139\n",
      "Trial 77: score = 0.6835853181222584\n",
      "Trial 78: score = 0.6953713561774226\n",
      "Trial 79: score = 0.6953713561774226\n",
      "Trial 80: score = 0.6864878979323246\n",
      "Trial 81: score = 0.6953713561774226\n",
      "Trial 82: score = 0.6953713561774226\n",
      "Trial 83: score = 0.6895955892394381\n",
      "Trial 84: score = 0.6835853181222584\n",
      "Trial 85: score = 0.6953713561774226\n",
      "Trial 86: score = 0.6953713561774226\n",
      "Trial 87: score = 0.6834933642395139\n",
      "Trial 88: score = 0.674511479970232\n",
      "Trial 89: score = 0.6615413085886228\n",
      "Trial 90: score = 0.6835853181222584\n",
      "Trial 91: score = 0.666002130174009\n",
      "Trial 92: score = 0.6953713561774226\n",
      "Trial 93: score = 0.6953713561774226\n",
      "Trial 94: score = 0.682525002684992\n",
      "Trial 95: score = 0.6864878979323246\n",
      "Trial 96: score = 0.674511479970232\n",
      "Trial 97: score = 0.6953713561774226\n",
      "Trial 98: score = 0.6730512125213639\n",
      "Trial 99: score = 0.6834933642395139\n",
      "Trial 100: score = 0.6864878979323246\n",
      "Trial 101: score = 0.6763659823217737\n",
      "Trial 102: score = 0.682525002684992\n",
      "Trial 103: score = 0.6953713561774226\n",
      "Trial 104: score = 0.682525002684992\n",
      "Trial 105: score = 0.6475135425619651\n",
      "Trial 106: score = 0.6895955892394381\n",
      "Trial 107: score = 0.6835853181222584\n",
      "Trial 108: score = 0.6747669503644562\n",
      "Trial 109: score = 0.6730512125213639\n",
      "Trial 110: score = 0.6953713561774226\n",
      "Trial 111: score = 0.6693889971222757\n",
      "Trial 112: score = 0.6953713561774226\n",
      "Trial 113: score = 0.6895955892394381\n",
      "Trial 114: score = 0.6947397383096601\n",
      "Trial 115: score = 0.6864878979323246\n",
      "Trial 116: score = 0.682525002684992\n",
      "Trial 117: score = 0.6730512125213639\n",
      "Trial 118: score = 0.6827070501364\n",
      "Trial 119: score = 0.6953713561774226\n",
      "Trial 120: score = 0.6895955892394381\n",
      "Trial 121: score = 0.681391289128906\n",
      "Trial 122: score = 0.6953713561774226\n",
      "Trial 123: score = 0.6864878979323246\n",
      "Trial 124: score = 0.666002130174009\n",
      "Trial 125: score = 0.682525002684992\n",
      "Trial 126: score = 0.6835853181222584\n",
      "Trial 127: score = 0.6749340041137067\n",
      "Trial 128: score = 0.674511479970232\n",
      "Trial 129: score = 0.6895955892394381\n",
      "Trial 130: score = 0.6730512125213639\n",
      "Trial 131: score = 0.6834933642395139\n",
      "Trial 132: score = 0.682525002684992\n",
      "Trial 133: score = 0.6953713561774226\n",
      "Trial 134: score = 0.6864878979323246\n",
      "Trial 135: score = 0.6947397383096601\n",
      "Trial 136: score = 0.6840517105951287\n",
      "Trial 137: score = 0.6895955892394381\n",
      "Trial 138: score = 0.6835853181222584\n",
      "Trial 139: score = 0.6953713561774226\n",
      "Trial 140: score = 0.6947397383096601\n",
      "Trial 141: score = 0.6827070501364\n",
      "Trial 142: score = 0.6953713561774226\n",
      "Trial 143: score = 0.682525002684992\n",
      "Trial 144: score = 0.6864878979323246\n",
      "Trial 145: score = 0.6953713561774226\n",
      "Trial 146: score = 0.6767085087424425\n",
      "Trial 147: score = 0.6895955892394381\n",
      "Trial 148: score = 0.6629879860691127\n",
      "Trial 149: score = 0.6864878979323246\n",
      "Trial 150: score = 0.6834933642395139\n",
      "Trial 151: score = 0.6947397383096601\n",
      "Trial 152: score = 0.6953713561774226\n",
      "Trial 153: score = 0.6895955892394381\n",
      "Trial 154: score = 0.682525002684992\n",
      "Trial 155: score = 0.6953713561774226\n",
      "Trial 156: score = 0.6835853181222584\n",
      "Trial 157: score = 0.6947397383096601\n",
      "Trial 158: score = 0.6895955892394381\n",
      "Trial 159: score = 0.682525002684992\n",
      "Trial 160: score = 0.6827070501364\n",
      "Trial 161: score = 0.6953713561774226\n",
      "Trial 162: score = 0.6895955892394381\n",
      "Trial 163: score = 0.6953713561774226\n",
      "Trial 164: score = 0.6864878979323246\n",
      "Trial 165: score = 0.6730512125213639\n",
      "Trial 166: score = 0.6947397383096601\n",
      "Trial 167: score = 0.6895955892394381\n",
      "Trial 168: score = 0.6852827443943703\n",
      "Trial 169: score = 0.6835853181222584\n",
      "Trial 170: score = 0.6820211808691401\n",
      "Trial 171: score = 0.6749340041137067\n",
      "Trial 172: score = 0.6953713561774226\n",
      "Trial 173: score = 0.6953713561774226\n",
      "Trial 174: score = 0.6864878979323246\n",
      "Trial 175: score = 0.682525002684992\n",
      "Trial 176: score = 0.6895955892394381\n",
      "Trial 177: score = 0.6947397383096601\n",
      "Trial 178: score = 0.6864878979323246\n",
      "Trial 179: score = 0.682525002684992\n",
      "Trial 180: score = 0.6760411191778001\n",
      "Trial 181: score = 0.6953713561774226\n",
      "Trial 182: score = 0.6953713561774226\n",
      "Trial 183: score = 0.6895955892394381\n",
      "Trial 184: score = 0.6947397383096601\n",
      "Trial 185: score = 0.682525002684992\n",
      "Trial 186: score = 0.6835853181222584\n",
      "Trial 187: score = 0.6953713561774226\n",
      "Trial 188: score = 0.6730512125213639\n",
      "Trial 189: score = 0.6895955892394381\n",
      "Trial 190: score = 0.6864878979323246\n",
      "Trial 191: score = 0.682525002684992\n",
      "Trial 192: score = 0.6953713561774226\n",
      "Trial 193: score = 0.6953713561774226\n",
      "Trial 194: score = 0.6947397383096601\n",
      "Trial 195: score = 0.6895955892394381\n",
      "Trial 196: score = 0.6953713561774226\n",
      "Trial 197: score = 0.6895955892394381\n",
      "Trial 198: score = 0.6864878979323246\n",
      "Trial 199: score = 0.6852827443943703\n",
      "Trial 200: score = 0.6784847878931931\n",
      "Trial 201: score = 0.682525002684992\n",
      "Trial 202: score = 0.6953713561774226\n",
      "Trial 203: score = 0.6953713561774226\n",
      "Trial 204: score = 0.6895955892394381\n",
      "Trial 205: score = 0.682525002684992\n",
      "Trial 206: score = 0.6864878979323246\n",
      "Trial 207: score = 0.6730512125213639\n",
      "Trial 208: score = 0.6953713561774226\n",
      "Trial 209: score = 0.6947397383096601\n",
      "Trial 210: score = 0.6835853181222584\n",
      "Trial 211: score = 0.6895955892394381\n",
      "Trial 212: score = 0.6953713561774226\n",
      "Trial 213: score = 0.682525002684992\n",
      "Trial 214: score = 0.6953713561774226\n",
      "Trial 215: score = 0.6895955892394381\n",
      "Trial 216: score = 0.682525002684992\n",
      "Trial 217: score = 0.6864878979323246\n",
      "Trial 218: score = 0.6953713561774226\n",
      "Trial 219: score = 0.6895955892394381\n",
      "Trial 220: score = 0.6947397383096601\n",
      "Trial 221: score = 0.682525002684992\n",
      "Trial 222: score = 0.6953713561774226\n",
      "Trial 223: score = 0.6953713561774226\n",
      "Trial 224: score = 0.6693889971222757\n",
      "Trial 225: score = 0.6864878979323246\n",
      "Trial 226: score = 0.6895955892394381\n",
      "Trial 227: score = 0.6953713561774226\n",
      "Trial 228: score = 0.682525002684992\n",
      "Trial 229: score = 0.6895955892394381\n",
      "Trial 230: score = 0.681391289128906\n",
      "Trial 231: score = 0.6730512125213639\n",
      "Trial 232: score = 0.6953713561774226\n",
      "Trial 233: score = 0.6953713561774226\n",
      "Trial 234: score = 0.682525002684992\n",
      "Trial 235: score = 0.6895955892394381\n",
      "Trial 236: score = 0.6953713561774226\n",
      "Trial 237: score = 0.6629879860691127\n",
      "Trial 238: score = 0.6864878979323246\n",
      "Trial 239: score = 0.6895955892394381\n",
      "Trial 240: score = 0.6743621893058414\n",
      "Trial 241: score = 0.682525002684992\n",
      "Trial 242: score = 0.6953713561774226\n",
      "Trial 243: score = 0.6953713561774226\n",
      "Trial 244: score = 0.6895955892394381\n",
      "Trial 245: score = 0.6947397383096601\n",
      "Trial 246: score = 0.6953713561774226\n",
      "Trial 247: score = 0.6864878979323246\n",
      "Trial 248: score = 0.682525002684992\n",
      "Trial 249: score = 0.6953713561774226\n",
      "Trial 250: score = 0.6895955892394381\n",
      "Trial 251: score = 0.6947397383096601\n",
      "Trial 252: score = 0.6835853181222584\n",
      "Trial 253: score = 0.682525002684992\n",
      "Trial 254: score = 0.6895955892394381\n",
      "Trial 255: score = 0.6953713561774226\n",
      "Trial 256: score = 0.6864878979323246\n",
      "Trial 257: score = 0.6947397383096601\n",
      "Trial 258: score = 0.6852827443943703\n",
      "Trial 259: score = 0.6864878979323246\n",
      "Trial 260: score = 0.6749340041137067\n",
      "Trial 261: score = 0.6953713561774226\n",
      "Trial 262: score = 0.6730512125213639\n",
      "Trial 263: score = 0.6895955892394381\n",
      "Trial 264: score = 0.682525002684992\n",
      "Trial 265: score = 0.6895955892394381\n",
      "Trial 266: score = 0.6835853181222584\n",
      "Trial 267: score = 0.682525002684992\n",
      "Trial 268: score = 0.6947397383096601\n",
      "Trial 269: score = 0.6953713561774226\n",
      "Trial 270: score = 0.6864878979323246\n",
      "Trial 271: score = 0.6953713561774226\n",
      "Trial 272: score = 0.6895955892394381\n",
      "Trial 273: score = 0.6834933642395139\n",
      "Trial 274: score = 0.682525002684992\n",
      "Trial 275: score = 0.6947397383096601\n",
      "Trial 276: score = 0.6895955892394381\n",
      "Trial 277: score = 0.682525002684992\n",
      "Trial 278: score = 0.6835853181222584\n",
      "Trial 279: score = 0.6749340041137067\n",
      "Trial 280: score = 0.6895955892394381\n",
      "Trial 281: score = 0.6864878979323246\n",
      "Trial 282: score = 0.6947397383096601\n",
      "Trial 283: score = 0.6730512125213639\n",
      "Trial 284: score = 0.6953713561774226\n",
      "Trial 285: score = 0.682525002684992\n",
      "Trial 286: score = 0.6895955892394381\n",
      "Trial 287: score = 0.6953713561774226\n",
      "Trial 288: score = 0.682525002684992\n",
      "Trial 289: score = 0.6864878979323246\n",
      "Trial 290: score = 0.6953713561774226\n",
      "Trial 291: score = 0.6947397383096601\n",
      "Trial 292: score = 0.6751503737951569\n",
      "Trial 293: score = 0.6895955892394381\n",
      "Trial 294: score = 0.6617942140159512\n",
      "Trial 295: score = 0.6827070501364\n",
      "Trial 296: score = 0.6852827443943703\n",
      "Trial 297: score = 0.6895955892394381\n",
      "Trial 298: score = 0.6835853181222584\n",
      "Trial 299: score = 0.6749340041137067\n",
      "Trial 300: score = 0.6730512125213639\n",
      "Trial 301: score = 0.6947397383096601\n",
      "Trial 302: score = 0.6864878979323246\n",
      "Trial 303: score = 0.682525002684992\n",
      "Trial 304: score = 0.6953713561774226\n",
      "Trial 305: score = 0.6895955892394381\n",
      "Trial 306: score = 0.682525002684992\n",
      "Trial 307: score = 0.6834933642395139\n",
      "Trial 308: score = 0.6953713561774226\n",
      "Trial 309: score = 0.6463456861668171\n",
      "Trial 310: score = 0.6895955892394381\n",
      "Trial 311: score = 0.6864878979323246\n",
      "Trial 312: score = 0.6953713561774226\n",
      "Trial 313: score = 0.6947397383096601\n",
      "Trial 314: score = 0.682525002684992\n",
      "Trial 315: score = 0.6875513424837653\n",
      "Trial 316: score = 0.6835853181222584\n",
      "Trial 317: score = 0.682525002684992\n",
      "Trial 318: score = 0.6713062630026033\n",
      "Trial 319: score = 0.6953713561774226\n",
      "Trial 320: score = 0.6730512125213639\n",
      "Trial 321: score = 0.6953713561774226\n",
      "Trial 322: score = 0.6895955892394381\n",
      "Trial 323: score = 0.6947397383096601\n",
      "Trial 324: score = 0.682525002684992\n",
      "Trial 325: score = 0.6864878979323246\n",
      "Trial 326: score = 0.6953713561774226\n",
      "Trial 327: score = 0.6895955892394381\n",
      "Trial 328: score = 0.682525002684992\n",
      "Trial 329: score = 0.6827070501364\n",
      "Trial 330: score = 0.6947397383096601\n",
      "Trial 331: score = 0.6953713561774226\n",
      "Trial 332: score = 0.6864878979323246\n",
      "Trial 333: score = 0.6895955892394381\n",
      "Trial 334: score = 0.6760411191778001\n",
      "Trial 335: score = 0.681391289128906\n",
      "Trial 336: score = 0.682525002684992\n",
      "Trial 337: score = 0.6749340041137067\n",
      "Trial 338: score = 0.6895955892394381\n",
      "Trial 339: score = 0.6730512125213639\n",
      "Trial 340: score = 0.682525002684992\n",
      "Trial 341: score = 0.6953713561774226\n",
      "Trial 342: score = 0.6776250828255701\n",
      "Trial 343: score = 0.6835853181222584\n",
      "Trial 344: score = 0.6895955892394381\n",
      "Trial 345: score = 0.6864878979323246\n",
      "Trial 346: score = 0.682525002684992\n",
      "Trial 347: score = 0.6953713561774226\n",
      "Trial 348: score = 0.6947397383096601\n",
      "Trial 349: score = 0.6895955892394381\n",
      "Trial 350: score = 0.6864878979323246\n",
      "Trial 351: score = 0.6834933642395139\n",
      "Trial 352: score = 0.6953713561774226\n",
      "Trial 353: score = 0.682525002684992\n",
      "Trial 354: score = 0.681391289128906\n",
      "Trial 355: score = 0.6953713561774226\n",
      "Trial 356: score = 0.6667428039121075\n",
      "Trial 357: score = 0.6786650574392814\n",
      "Trial 358: score = 0.6512882461796787\n",
      "Trial 359: score = 0.682525002684992\n",
      "Trial 360: score = 0.6730512125213639\n",
      "Trial 361: score = 0.6864878979323246\n",
      "Trial 362: score = 0.6953713561774226\n",
      "Trial 363: score = 0.6835853181222584\n",
      "Trial 364: score = 0.6895955892394381\n",
      "Trial 365: score = 0.682525002684992\n",
      "Trial 366: score = 0.6953713561774226\n",
      "Trial 367: score = 0.6947397383096601\n",
      "Trial 368: score = 0.6895955892394381\n",
      "Trial 369: score = 0.6953713561774226\n",
      "Trial 370: score = 0.6864878979323246\n",
      "Trial 371: score = 0.6840517105951287\n",
      "Trial 372: score = 0.682525002684992\n",
      "Trial 373: score = 0.681391289128906\n",
      "Trial 374: score = 0.6895955892394381\n",
      "Trial 375: score = 0.6953713561774226\n",
      "Trial 376: score = 0.680265174092224\n",
      "Trial 377: score = 0.682525002684992\n",
      "Trial 378: score = 0.6864878979323246\n",
      "Trial 379: score = 0.6730512125213639\n",
      "Trial 380: score = 0.6885454602923601\n",
      "Trial 381: score = 0.6895955892394381\n",
      "Trial 382: score = 0.6667944703066147\n",
      "Trial 383: score = 0.682525002684992\n",
      "Trial 384: score = 0.6835853181222584\n",
      "Trial 385: score = 0.6953713561774226\n",
      "Trial 386: score = 0.6947397383096601\n",
      "Trial 387: score = 0.6895955892394381\n",
      "Trial 388: score = 0.682525002684992\n",
      "Trial 389: score = 0.6953713561774226\n",
      "Trial 390: score = 0.6895955892394381\n",
      "Trial 391: score = 0.6864878979323246\n",
      "Trial 392: score = 0.6835424806310899\n",
      "Trial 393: score = 0.666002130174009\n",
      "Trial 394: score = 0.6730512125213639\n",
      "Trial 395: score = 0.6629879860691127\n",
      "Trial 396: score = 0.6953713561774226\n",
      "Trial 397: score = 0.6947397383096601\n",
      "Trial 398: score = 0.6895955892394381\n",
      "Trial 399: score = 0.6835853181222584\n",
      "Trial 400: score = 0.6864878979323246\n",
      "Trial 401: score = 0.6947397383096601\n",
      "Trial 402: score = 0.682525002684992\n",
      "Trial 403: score = 0.6953713561774226\n",
      "Trial 404: score = 0.6895955892394381\n",
      "Trial 405: score = 0.674511479970232\n",
      "Trial 406: score = 0.682525002684992\n",
      "Trial 407: score = 0.6953713561774226\n",
      "Trial 408: score = 0.6895955892394381\n",
      "Trial 409: score = 0.6864878979323246\n",
      "Trial 410: score = 0.6834933642395139\n",
      "Trial 411: score = 0.6852827443943703\n",
      "Trial 412: score = 0.6895955892394381\n",
      "Trial 413: score = 0.6953713561774226\n",
      "Trial 414: score = 0.6947397383096601\n",
      "Trial 415: score = 0.6705849937481491\n",
      "Trial 416: score = 0.6953713561774226\n",
      "Trial 417: score = 0.6864878979323246\n",
      "Trial 418: score = 0.682525002684992\n",
      "Trial 419: score = 0.6947397383096601\n",
      "Trial 420: score = 0.6895955892394381\n",
      "Trial 421: score = 0.6835853181222584\n",
      "Trial 422: score = 0.6953713561774226\n",
      "Trial 423: score = 0.6895955892394381\n",
      "Trial 424: score = 0.6730512125213639\n",
      "Trial 425: score = 0.682525002684992\n",
      "Trial 426: score = 0.6953713561774226\n",
      "Trial 427: score = 0.6864878979323246\n",
      "Trial 428: score = 0.682525002684992\n",
      "Trial 429: score = 0.6852113713817654\n",
      "Trial 430: score = 0.681391289128906\n",
      "Trial 431: score = 0.6895955892394381\n",
      "Trial 432: score = 0.6835853181222584\n",
      "Trial 433: score = 0.6758573010257425\n",
      "Trial 434: score = 0.6749340041137067\n",
      "Trial 435: score = 0.682525002684992\n",
      "Trial 436: score = 0.6730512125213639\n",
      "Trial 437: score = 0.6864878979323246\n",
      "Trial 438: score = 0.6953713561774226\n",
      "Trial 439: score = 0.6475135425619651\n",
      "Trial 440: score = 0.6895955892394381\n",
      "Trial 441: score = 0.6947397383096601\n",
      "Trial 442: score = 0.682525002684992\n",
      "Trial 443: score = 0.6953713561774226\n",
      "Trial 444: score = 0.6895955892394381\n",
      "Trial 445: score = 0.6827070501364\n",
      "Trial 446: score = 0.6864878979323246\n",
      "Trial 447: score = 0.682525002684992\n",
      "Trial 448: score = 0.6953713561774226\n",
      "Trial 449: score = 0.6875513424837653\n",
      "Trial 450: score = 0.6947397383096601\n",
      "Trial 451: score = 0.682525002684992\n",
      "Trial 452: score = 0.6667428039121075\n",
      "Trial 453: score = 0.6864878979323246\n",
      "Trial 454: score = 0.6953713561774226\n",
      "Trial 455: score = 0.6947397383096601\n",
      "Trial 456: score = 0.6953713561774226\n",
      "Trial 457: score = 0.6835853181222584\n",
      "Trial 458: score = 0.6730512125213639\n",
      "Trial 459: score = 0.682525002684992\n",
      "Trial 460: score = 0.6953713561774226\n",
      "Trial 461: score = 0.6895955892394381\n",
      "Trial 462: score = 0.682525002684992\n",
      "Trial 463: score = 0.6834933642395139\n",
      "Trial 464: score = 0.6864878979323246\n",
      "Trial 465: score = 0.6953713561774226\n",
      "Trial 466: score = 0.6947397383096601\n",
      "Trial 467: score = 0.6895955892394381\n",
      "Trial 468: score = 0.6835424806310899\n",
      "Trial 469: score = 0.6864878979323246\n",
      "Trial 470: score = 0.682525002684992\n",
      "Trial 471: score = 0.6667428039121075\n",
      "Trial 472: score = 0.6947397383096601\n",
      "Trial 473: score = 0.682525002684992\n",
      "Trial 474: score = 0.6835853181222584\n",
      "Trial 475: score = 0.6654420182811671\n",
      "Trial 476: score = 0.6953713561774226\n",
      "Trial 477: score = 0.6895955892394381\n",
      "Trial 478: score = 0.682525002684992\n",
      "Trial 479: score = 0.6730512125213639\n",
      "Trial 480: score = 0.6864878979323246\n",
      "Trial 481: score = 0.6953713561774226\n",
      "Trial 482: score = 0.682525002684992\n",
      "Trial 483: score = 0.6895955892394381\n",
      "Trial 484: score = 0.674511479970232\n",
      "Trial 485: score = 0.6947397383096601\n",
      "Trial 486: score = 0.6953713561774226\n",
      "Trial 487: score = 0.6559879863070786\n",
      "Trial 488: score = 0.6895955892394381\n",
      "Trial 489: score = 0.6827070501364\n",
      "Trial 490: score = 0.6829237207664021\n",
      "Trial 491: score = 0.6864878979323246\n",
      "Trial 492: score = 0.6953713561774226\n",
      "Trial 493: score = 0.6947397383096601\n",
      "Trial 494: score = 0.682525002684992\n",
      "Trial 495: score = 0.6895955892394381\n",
      "Trial 496: score = 0.6840517105951287\n",
      "Trial 497: score = 0.6953713561774226\n",
      "Trial 498: score = 0.6864878979323246\n",
      "Trial 499: score = 0.682525002684992\n",
      "Trial 500: score = 0.6835853181222584\n",
      "Trial 501: score = 0.6895955892394381\n",
      "Trial 502: score = 0.6953713561774226\n",
      "Trial 503: score = 0.6947397383096601\n",
      "Trial 504: score = 0.682525002684992\n",
      "Trial 505: score = 0.6834933642395139\n",
      "Trial 506: score = 0.6753793754122858\n",
      "Trial 507: score = 0.6895955892394381\n",
      "Trial 508: score = 0.6953713561774226\n",
      "Trial 509: score = 0.6713062630026033\n",
      "Trial 510: score = 0.682525002684992\n",
      "Trial 511: score = 0.6730512125213639\n",
      "Trial 512: score = 0.6953713561774226\n",
      "Trial 513: score = 0.6895955892394381\n",
      "Trial 514: score = 0.6947397383096601\n",
      "Trial 515: score = 0.6864878979323246\n",
      "Trial 516: score = 0.684626103722526\n",
      "Trial 517: score = 0.6953713561774226\n",
      "Trial 518: score = 0.682525002684992\n",
      "Trial 519: score = 0.6895955892394381\n",
      "Trial 520: score = 0.6835853181222584\n",
      "Trial 521: score = 0.682525002684992\n",
      "Trial 522: score = 0.6953713561774226\n",
      "Trial 523: score = 0.6947397383096601\n",
      "Trial 524: score = 0.6895955892394381\n",
      "Trial 525: score = 0.6835424806310899\n",
      "Trial 526: score = 0.6864878979323246\n",
      "Trial 527: score = 0.682525002684992\n",
      "Trial 528: score = 0.6738444227705085\n",
      "Trial 529: score = 0.6947397383096601\n",
      "Trial 530: score = 0.6895955892394381\n",
      "Trial 531: score = 0.6953713561774226\n",
      "Trial 532: score = 0.682525002684992\n",
      "Trial 533: score = 0.6895955892394381\n",
      "Trial 534: score = 0.6730512125213639\n",
      "Trial 535: score = 0.6864878979323246\n",
      "Trial 536: score = 0.666002130174009\n",
      "Trial 537: score = 0.6835853181222584\n",
      "Trial 538: score = 0.6953713561774226\n",
      "Trial 539: score = 0.682525002684992\n",
      "Trial 540: score = 0.6895955892394381\n",
      "Trial 541: score = 0.6827070501364\n",
      "Trial 542: score = 0.6953713561774226\n",
      "Trial 543: score = 0.6947397383096601\n",
      "Trial 544: score = 0.6852827443943703\n",
      "Trial 545: score = 0.6895955892394381\n",
      "Trial 546: score = 0.6743621893058414\n",
      "Trial 547: score = 0.6713062630026033\n",
      "Trial 548: score = 0.6953713561774226\n",
      "Trial 549: score = 0.6947397383096601\n",
      "Trial 550: score = 0.6953713561774226\n",
      "Trial 551: score = 0.6864878979323246\n",
      "Trial 552: score = 0.6667944703066147\n",
      "Trial 553: score = 0.682525002684992\n",
      "Trial 554: score = 0.6730512125213639\n",
      "Trial 555: score = 0.6895955892394381\n",
      "Trial 556: score = 0.6953713561774226\n",
      "Trial 557: score = 0.682525002684992\n",
      "Trial 558: score = 0.6895955892394381\n",
      "Trial 559: score = 0.682525002684992\n",
      "Trial 560: score = 0.6947397383096601\n",
      "Trial 561: score = 0.6864878979323246\n",
      "Trial 562: score = 0.6835853181222584\n",
      "Trial 563: score = 0.6953713561774226\n",
      "Trial 564: score = 0.681391289128906\n",
      "Trial 565: score = 0.6895955892394381\n",
      "Trial 566: score = 0.6749340041137067\n",
      "Trial 567: score = 0.682525002684992\n",
      "Trial 568: score = 0.6895955892394381\n",
      "Trial 569: score = 0.6835853181222584\n",
      "Trial 570: score = 0.6834933642395139\n",
      "Trial 571: score = 0.6953713561774226\n",
      "Trial 572: score = 0.682525002684992\n",
      "Trial 573: score = 0.6895955892394381\n",
      "Trial 574: score = 0.6953713561774226\n",
      "Trial 575: score = 0.6864878979323246\n",
      "Trial 576: score = 0.682525002684992\n",
      "Trial 577: score = 0.6730512125213639\n",
      "Trial 578: score = 0.6864878979323246\n",
      "Trial 579: score = 0.6947397383096601\n",
      "Trial 580: score = 0.6904910810307511\n",
      "Trial 581: score = 0.6953713561774226\n",
      "Trial 582: score = 0.6875513424837653\n",
      "Trial 583: score = 0.6947397383096601\n",
      "Trial 584: score = 0.682525002684992\n",
      "Trial 585: score = 0.6749340041137067\n",
      "Trial 586: score = 0.6895955892394381\n",
      "Trial 587: score = 0.6864878979323246\n",
      "Trial 588: score = 0.682525002684992\n",
      "Trial 589: score = 0.6730512125213639\n",
      "Trial 590: score = 0.6953713561774226\n",
      "Trial 591: score = 0.682525002684992\n",
      "Trial 592: score = 0.6835853181222584\n",
      "Trial 593: score = 0.6895955892394381\n",
      "Trial 594: score = 0.6947397383096601\n",
      "Trial 595: score = 0.6953713561774226\n",
      "Trial 596: score = 0.6895955892394381\n",
      "Trial 597: score = 0.6864878979323246\n",
      "Trial 598: score = 0.6953713561774226\n",
      "Trial 599: score = 0.6947397383096601\n",
      "Trial 600: score = 0.682525002684992\n",
      "Trial 601: score = 0.6835424806310899\n",
      "Trial 602: score = 0.6895955892394381\n",
      "Trial 603: score = 0.6834933642395139\n",
      "Trial 604: score = 0.6713062630026033\n",
      "Trial 605: score = 0.6953713561774226\n",
      "Trial 606: score = 0.6835853181222584\n",
      "Trial 607: score = 0.682525002684992\n",
      "Trial 608: score = 0.6827070501364\n",
      "Trial 609: score = 0.6895955892394381\n",
      "Trial 610: score = 0.682525002684992\n",
      "Trial 611: score = 0.6947397383096601\n",
      "Trial 612: score = 0.6895955892394381\n",
      "Trial 613: score = 0.6953713561774226\n",
      "Trial 614: score = 0.6947397383096601\n",
      "Trial 615: score = 0.6953713561774226\n",
      "Trial 616: score = 0.6730512125213639\n",
      "Trial 617: score = 0.6864878979323246\n",
      "Trial 618: score = 0.682525002684992\n",
      "Trial 619: score = 0.6895955892394381\n",
      "Trial 620: score = 0.6713165077374927\n",
      "Trial 621: score = 0.682525002684992\n",
      "Trial 622: score = 0.6835424806310899\n",
      "Trial 623: score = 0.6713062630026033\n",
      "Trial 624: score = 0.6947397383096601\n",
      "Trial 625: score = 0.6895955892394381\n",
      "Trial 626: score = 0.6953713561774226\n",
      "Trial 627: score = 0.682525002684992\n",
      "Trial 628: score = 0.674511479970232\n",
      "Trial 629: score = 0.6617942140159512\n",
      "Trial 630: score = 0.6730512125213639\n",
      "Trial 631: score = 0.6864878979323246\n",
      "Trial 632: score = 0.6895955892394381\n",
      "Trial 633: score = 0.6835853181222584\n",
      "Trial 634: score = 0.682525002684992\n",
      "Trial 635: score = 0.6953713561774226\n",
      "Trial 636: score = 0.6953713561774226\n",
      "Trial 637: score = 0.6895955892394381\n",
      "Trial 638: score = 0.6947397383096601\n",
      "Trial 639: score = 0.6852827443943703\n",
      "Trial 640: score = 0.6929523447947359\n",
      "Trial 641: score = 0.6953713561774226\n",
      "Trial 642: score = 0.6713062630026033\n",
      "Trial 643: score = 0.6895955892394381\n",
      "Trial 644: score = 0.6827070501364\n",
      "Trial 645: score = 0.666002130174009\n",
      "Trial 646: score = 0.6947397383096601\n",
      "Trial 647: score = 0.6953713561774226\n",
      "Trial 648: score = 0.682525002684992\n",
      "Trial 649: score = 0.6895955892394381\n",
      "Trial 650: score = 0.682525002684992\n",
      "Trial 651: score = 0.6864878979323246\n",
      "Trial 652: score = 0.6730512125213639\n",
      "Trial 653: score = 0.6835853181222584\n",
      "Trial 654: score = 0.6953713561774226\n",
      "Trial 655: score = 0.6773161908892508\n",
      "Trial 656: score = 0.6947397383096601\n",
      "Trial 657: score = 0.6895955892394381\n",
      "Trial 658: score = 0.6835424806310899\n",
      "Trial 659: score = 0.682525002684992\n",
      "Trial 660: score = 0.6895955892394381\n",
      "Trial 661: score = 0.6749340041137067\n",
      "Trial 662: score = 0.6864878979323246\n",
      "Trial 663: score = 0.6947397383096601\n",
      "Trial 664: score = 0.6738455719724926\n",
      "Trial 665: score = 0.682525002684992\n",
      "Trial 666: score = 0.6953713561774226\n",
      "Trial 667: score = 0.6895955892394381\n",
      "Trial 668: score = 0.6835853181222584\n",
      "Trial 669: score = 0.6730512125213639\n",
      "Trial 670: score = 0.682525002684992\n",
      "Trial 671: score = 0.6895955892394381\n",
      "Trial 672: score = 0.6864878979323246\n",
      "Trial 673: score = 0.682525002684992\n",
      "Trial 674: score = 0.6953713561774226\n",
      "Trial 675: score = 0.6895955892394381\n",
      "Trial 676: score = 0.6947397383096601\n",
      "Trial 677: score = 0.6835424806310899\n",
      "Trial 678: score = 0.6834933642395139\n",
      "Trial 679: score = 0.682525002684992\n",
      "Trial 680: score = 0.6885454602923601\n",
      "Trial 681: score = 0.6864878979323246\n",
      "Trial 682: score = 0.6749340041137067\n",
      "Trial 683: score = 0.6730512125213639\n",
      "Trial 684: score = 0.6895955892394381\n",
      "Trial 685: score = 0.6947397383096601\n",
      "Trial 686: score = 0.6740139389007049\n",
      "Trial 687: score = 0.682525002684992\n",
      "Trial 688: score = 0.6835853181222584\n",
      "Trial 689: score = 0.6895955892394381\n",
      "Trial 690: score = 0.6953713561774226\n",
      "Trial 691: score = 0.6864878979323246\n",
      "Trial 692: score = 0.6953713561774226\n",
      "Trial 693: score = 0.6947397383096601\n",
      "Trial 694: score = 0.682525002684992\n",
      "Trial 695: score = 0.6895955892394381\n",
      "Trial 696: score = 0.6835424806310899\n",
      "Trial 697: score = 0.6864878979323246\n",
      "Trial 698: score = 0.6629879860691127\n",
      "Trial 699: score = 0.6947397383096601\n",
      "Trial 700: score = 0.6835853181222584\n",
      "Trial 701: score = 0.6895955892394381\n",
      "Trial 702: score = 0.6953713561774226\n",
      "Trial 703: score = 0.682525002684992\n",
      "Trial 704: score = 0.6895955892394381\n",
      "Trial 705: score = 0.6820211808691401\n",
      "Trial 706: score = 0.6834933642395139\n",
      "Trial 707: score = 0.6953713561774226\n",
      "Trial 708: score = 0.6730512125213639\n",
      "Trial 709: score = 0.6614497222143254\n",
      "Trial 710: score = 0.6864878979323246\n",
      "Trial 711: score = 0.6947397383096601\n",
      "Trial 712: score = 0.682525002684992\n",
      "Trial 713: score = 0.6895955892394381\n",
      "Trial 714: score = 0.682525002684992\n",
      "Trial 715: score = 0.6763659823217737\n",
      "Trial 716: score = 0.6953713561774226\n",
      "Trial 717: score = 0.6667428039121075\n",
      "Trial 718: score = 0.6953713561774226\n",
      "Trial 719: score = 0.6864878979323246\n",
      "Trial 720: score = 0.6947397383096601\n",
      "Trial 721: score = 0.6953713561774226\n",
      "Trial 722: score = 0.682525002684992\n",
      "Trial 723: score = 0.6895955892394381\n",
      "Trial 724: score = 0.6864878979323246\n",
      "Trial 725: score = 0.682525002684992\n",
      "Trial 726: score = 0.6953713561774226\n",
      "Trial 727: score = 0.6730512125213639\n",
      "Trial 728: score = 0.6835853181222584\n",
      "Trial 729: score = 0.6895955892394381\n",
      "Trial 730: score = 0.674511479970232\n",
      "Trial 731: score = 0.6953713561774226\n",
      "Trial 732: score = 0.6947397383096601\n",
      "Trial 733: score = 0.682525002684992\n",
      "Trial 734: score = 0.6795273267388691\n",
      "Trial 735: score = 0.6895955892394381\n",
      "Trial 736: score = 0.6749340041137067\n",
      "Trial 737: score = 0.6947397383096601\n",
      "Trial 738: score = 0.682525002684992\n",
      "Trial 739: score = 0.6895955892394381\n",
      "Trial 740: score = 0.6835853181222584\n",
      "Trial 741: score = 0.6953713561774226\n",
      "Trial 742: score = 0.6864878979323246\n",
      "Trial 743: score = 0.6730512125213639\n",
      "Trial 744: score = 0.682525002684992\n",
      "Trial 745: score = 0.6895955892394381\n",
      "Trial 746: score = 0.6953713561774226\n",
      "Trial 747: score = 0.682525002684992\n",
      "Trial 748: score = 0.6895955892394381\n",
      "Trial 749: score = 0.682525002684992\n",
      "Trial 750: score = 0.6947397383096601\n",
      "Trial 751: score = 0.6953713561774226\n",
      "Trial 752: score = 0.6795273267388691\n",
      "Trial 753: score = 0.6953713561774226\n",
      "Trial 754: score = 0.6895955892394381\n",
      "Trial 755: score = 0.6947397383096601\n",
      "Trial 756: score = 0.6749340041137067\n",
      "Trial 757: score = 0.6835853181222584\n",
      "Trial 758: score = 0.6730512125213639\n",
      "Trial 759: score = 0.6864878979323246\n",
      "Trial 760: score = 0.682525002684992\n",
      "Trial 761: score = 0.6786650574392814\n",
      "Trial 762: score = 0.6765765244497868\n",
      "Trial 763: score = 0.6895955892394381\n",
      "Trial 764: score = 0.682525002684992\n",
      "Trial 765: score = 0.6932016211341822\n",
      "Trial 766: score = 0.6953713561774226\n",
      "Trial 767: score = 0.6895955892394381\n",
      "Trial 768: score = 0.6947397383096601\n",
      "Trial 769: score = 0.6827070501364\n",
      "Trial 770: score = 0.6953713561774226\n",
      "Trial 771: score = 0.6864878979323246\n",
      "Trial 772: score = 0.6667765565710615\n",
      "Trial 773: score = 0.6947397383096601\n",
      "Trial 774: score = 0.6667428039121075\n",
      "Trial 775: score = 0.682525002684992\n",
      "Trial 776: score = 0.6834933642395139\n",
      "Trial 777: score = 0.6953713561774226\n",
      "Trial 778: score = 0.6895955892394381\n",
      "Trial 779: score = 0.6730512125213639\n",
      "Trial 780: score = 0.682525002684992\n",
      "Trial 781: score = 0.6953713561774226\n",
      "Trial 782: score = 0.6864878979323246\n",
      "Trial 783: score = 0.6947397383096601\n",
      "Trial 784: score = 0.682525002684992\n",
      "Trial 785: score = 0.6953713561774226\n",
      "Trial 786: score = 0.6758573010257425\n",
      "Trial 787: score = 0.6895955892394381\n",
      "Trial 788: score = 0.6864878979323246\n",
      "Trial 789: score = 0.6953713561774226\n",
      "Trial 790: score = 0.6835853181222584\n",
      "Trial 791: score = 0.6875513424837653\n",
      "Trial 792: score = 0.682525002684992\n",
      "Trial 793: score = 0.682525002684992\n",
      "Trial 794: score = 0.6829237207664021\n",
      "Trial 795: score = 0.6895955892394381\n",
      "Trial 796: score = 0.6947397383096601\n",
      "Trial 797: score = 0.6953713561774226\n",
      "Trial 798: score = 0.6953713561774226\n",
      "Trial 799: score = 0.6864878979323246\n",
      "Trial 800: score = 0.682525002684992\n",
      "Trial 801: score = 0.6864878979323246\n",
      "Trial 802: score = 0.6835853181222584\n",
      "Trial 803: score = 0.6895955892394381\n",
      "Trial 804: score = 0.6953713561774226\n",
      "Trial 805: score = 0.682525002684992\n",
      "Trial 806: score = 0.6947397383096601\n",
      "Trial 807: score = 0.6827070501364\n",
      "Trial 808: score = 0.6953713561774226\n",
      "Trial 809: score = 0.6475135425619651\n",
      "Trial 810: score = 0.6895955892394381\n",
      "Trial 811: score = 0.682525002684992\n",
      "Trial 812: score = 0.6667428039121075\n",
      "Trial 813: score = 0.6730512125213639\n",
      "Trial 814: score = 0.6953713561774226\n",
      "Trial 815: score = 0.6947397383096601\n",
      "Trial 816: score = 0.6864878979323246\n",
      "Trial 817: score = 0.6953713561774226\n",
      "Trial 818: score = 0.682525002684992\n",
      "Trial 819: score = 0.6947397383096601\n",
      "Trial 820: score = 0.6895955892394381\n",
      "Trial 821: score = 0.682525002684992\n",
      "Trial 822: score = 0.6864878979323246\n",
      "Trial 823: score = 0.6895955892394381\n",
      "Trial 824: score = 0.6835853181222584\n",
      "Trial 825: score = 0.6953713561774226\n",
      "Trial 826: score = 0.6834933642395139\n",
      "Trial 827: score = 0.682525002684992\n",
      "Trial 828: score = 0.6835424806310899\n",
      "Trial 829: score = 0.666002130174009\n",
      "Trial 830: score = 0.6947397383096601\n",
      "Trial 831: score = 0.6667428039121075\n",
      "Trial 832: score = 0.6953713561774226\n",
      "Trial 833: score = 0.6864878979323246\n",
      "Trial 834: score = 0.682525002684992\n",
      "Trial 835: score = 0.6953713561774226\n",
      "Trial 836: score = 0.6947397383096601\n",
      "Trial 837: score = 0.6895955892394381\n",
      "Trial 838: score = 0.6835853181222584\n",
      "Trial 839: score = 0.6730512125213639\n",
      "Trial 840: score = 0.682525002684992\n",
      "Trial 841: score = 0.6895955892394381\n",
      "Trial 842: score = 0.6953713561774226\n",
      "Trial 843: score = 0.6864878979323246\n",
      "Trial 844: score = 0.6639457300939448\n",
      "Trial 845: score = 0.6601343089951125\n",
      "Trial 846: score = 0.682525002684992\n",
      "Trial 847: score = 0.6875513424837653\n",
      "Trial 848: score = 0.6953713561774226\n",
      "Trial 849: score = 0.6947397383096601\n",
      "Trial 850: score = 0.6629879860691127\n",
      "Trial 851: score = 0.6864878979323246\n",
      "Trial 852: score = 0.6953713561774226\n",
      "Trial 853: score = 0.6895955892394381\n",
      "Trial 854: score = 0.6730512125213639\n",
      "Trial 855: score = 0.682525002684992\n",
      "Trial 856: score = 0.6835853181222584\n",
      "Trial 857: score = 0.6864878979323246\n",
      "Trial 858: score = 0.6947397383096601\n",
      "Trial 859: score = 0.6953713561774226\n",
      "Trial 860: score = 0.6895955892394381\n",
      "Trial 861: score = 0.6827070501364\n",
      "Trial 862: score = 0.682525002684992\n",
      "Trial 863: score = 0.6953713561774226\n",
      "Trial 864: score = 0.6895955892394381\n",
      "Trial 865: score = 0.6947397383096601\n",
      "Trial 866: score = 0.6852827443943703\n",
      "Trial 867: score = 0.6864878979323246\n",
      "Trial 868: score = 0.6749340041137067\n",
      "Trial 869: score = 0.6947397383096601\n",
      "Trial 870: score = 0.6895955892394381\n",
      "Trial 871: score = 0.6953713561774226\n",
      "Trial 872: score = 0.682525002684992\n",
      "Trial 873: score = 0.6895955892394381\n",
      "Trial 874: score = 0.6730512125213639\n",
      "Trial 875: score = 0.6784902486906266\n",
      "Trial 876: score = 0.6953713561774226\n",
      "Trial 877: score = 0.6864878979323246\n",
      "Trial 878: score = 0.6738455719724926\n",
      "Trial 879: score = 0.6786650574392814\n",
      "Trial 880: score = 0.682525002684992\n",
      "Trial 881: score = 0.6852113713817654\n",
      "Trial 882: score = 0.6895955892394381\n",
      "Trial 883: score = 0.6947397383096601\n",
      "Trial 884: score = 0.6751503737951569\n",
      "Trial 885: score = 0.6713955187213907\n",
      "Trial 886: score = 0.6835853181222584\n",
      "Trial 887: score = 0.6798823761294225\n",
      "Trial 888: score = 0.6953713561774226\n",
      "Trial 889: score = 0.6864878979323246\n",
      "Trial 890: score = 0.6953713561774226\n",
      "Trial 891: score = 0.682525002684992\n",
      "Trial 892: score = 0.6947397383096601\n",
      "Trial 893: score = 0.6895955892394381\n",
      "Trial 894: score = 0.682525002684992\n",
      "Trial 895: score = 0.6835853181222584\n",
      "Trial 896: score = 0.6953713561774226\n",
      "Trial 897: score = 0.6895955892394381\n",
      "Trial 898: score = 0.6953713561774226\n",
      "Trial 899: score = 0.6864878979323246\n",
      "Trial 900: score = 0.682525002684992\n",
      "Trial 901: score = 0.6895955892394381\n",
      "Trial 902: score = 0.6730512125213639\n",
      "Trial 903: score = 0.6852827443943703\n",
      "Trial 904: score = 0.6947397383096601\n",
      "Trial 905: score = 0.6953713561774226\n",
      "Trial 906: score = 0.6749340041137067\n",
      "Trial 907: score = 0.6835486963132398\n",
      "Trial 908: score = 0.6895955892394381\n",
      "Trial 909: score = 0.6864878979323246\n",
      "Trial 910: score = 0.6827070501364\n",
      "Trial 911: score = 0.6947397383096601\n",
      "Trial 912: score = 0.682525002684992\n",
      "Trial 913: score = 0.6953713561774226\n",
      "Trial 914: score = 0.6864878979323246\n",
      "Trial 915: score = 0.6895955892394381\n",
      "Trial 916: score = 0.6730512125213639\n",
      "Trial 917: score = 0.682525002684992\n",
      "Trial 918: score = 0.6953713561774226\n",
      "Trial 919: score = 0.6895955892394381\n",
      "Trial 920: score = 0.6835853181222584\n",
      "Trial 921: score = 0.6947397383096601\n",
      "Trial 922: score = 0.6835424806310899\n",
      "Trial 923: score = 0.682525002684992\n",
      "Trial 924: score = 0.6864878979323246\n",
      "Trial 925: score = 0.6834933642395139\n",
      "Trial 926: score = 0.6667428039121075\n",
      "Trial 927: score = 0.682525002684992\n",
      "Trial 928: score = 0.6953713561774226\n",
      "Trial 929: score = 0.6947397383096601\n",
      "Trial 930: score = 0.6895955892394381\n",
      "Trial 931: score = 0.6953713561774226\n",
      "Trial 932: score = 0.6541528948508011\n",
      "Trial 933: score = 0.6835853181222584\n",
      "Trial 934: score = 0.682525002684992\n",
      "Trial 935: score = 0.6895955892394381\n",
      "Trial 936: score = 0.6864878979323246\n",
      "Trial 937: score = 0.6953713561774226\n",
      "Trial 938: score = 0.6947397383096601\n",
      "Trial 939: score = 0.682525002684992\n",
      "Trial 940: score = 0.6730512125213639\n",
      "Trial 941: score = 0.6835424806310899\n",
      "Trial 942: score = 0.6895955892394381\n",
      "Trial 943: score = 0.6864878979323246\n",
      "Trial 944: score = 0.6629879860691127\n",
      "Trial 945: score = 0.6895955892394381\n",
      "Trial 946: score = 0.6953713561774226\n",
      "Trial 947: score = 0.6947397383096601\n",
      "Trial 948: score = 0.6864878979323246\n",
      "Trial 949: score = 0.6953713561774226\n",
      "Trial 950: score = 0.682525002684992\n",
      "Trial 951: score = 0.6895955892394381\n",
      "Trial 952: score = 0.6947397383096601\n",
      "Trial 953: score = 0.6953713561774226\n",
      "Trial 954: score = 0.682525002684992\n",
      "Trial 955: score = 0.6827070501364\n",
      "Trial 956: score = 0.6730512125213639\n",
      "Trial 957: score = 0.6895955892394381\n",
      "Trial 958: score = 0.682525002684992\n",
      "Trial 959: score = 0.6835853181222584\n",
      "Trial 960: score = 0.6864878979323246\n",
      "Trial 961: score = 0.6953713561774226\n",
      "Trial 962: score = 0.6665042281321919\n",
      "Trial 963: score = 0.6688299935424245\n",
      "Trial 964: score = 0.6895955892394381\n",
      "Trial 965: score = 0.6953713561774226\n",
      "Trial 966: score = 0.6895955892394381\n",
      "Trial 967: score = 0.682525002684992\n",
      "Trial 968: score = 0.6730512125213639\n",
      "Trial 969: score = 0.6953713561774226\n",
      "Trial 970: score = 0.6864878979323246\n",
      "Trial 971: score = 0.682525002684992\n",
      "Trial 972: score = 0.6895955892394381\n",
      "Trial 973: score = 0.6953713561774226\n",
      "Trial 974: score = 0.666002130174009\n",
      "Trial 975: score = 0.6835853181222584\n",
      "Trial 976: score = 0.674511479970232\n",
      "Trial 977: score = 0.6947397383096601\n",
      "Trial 978: score = 0.6864878979323246\n",
      "Trial 979: score = 0.6852827443943703\n",
      "Trial 980: score = 0.6953713561774226\n",
      "Trial 981: score = 0.6895955892394381\n",
      "Trial 982: score = 0.6784847878931931\n",
      "Trial 983: score = 0.682525002684992\n",
      "Trial 984: score = 0.6895955892394381\n",
      "Trial 985: score = 0.6953713561774226\n",
      "Trial 986: score = 0.6864878979323246\n",
      "Trial 987: score = 0.682525002684992\n",
      "Trial 988: score = 0.6730512125213639\n",
      "Trial 989: score = 0.6953713561774226\n",
      "Trial 990: score = 0.6947397383096601\n",
      "Trial 991: score = 0.6895955892394381\n",
      "Trial 992: score = 0.6864878979323246\n",
      "Trial 993: score = 0.6953713561774226\n",
      "Trial 994: score = 0.682525002684992\n",
      "Trial 995: score = 0.6512882461796787\n",
      "Trial 996: score = 0.6835853181222584\n",
      "Trial 997: score = 0.6895955892394381\n",
      "Trial 998: score = 0.6735271374554755\n",
      "Trial 999: score = 0.6947397383096601\n",
      "Trial 1000: score = 0.6953713561774226\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    model = KNeighborsClassifier(\n",
    "        n_neighbors=trial.suggest_int('n_neighbors', 1, 50),\n",
    "        weights=trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "        metric=trial.suggest_categorical('metric', ['euclidean', 'cosine']),\n",
    "        leaf_size=trial.suggest_int('leaf_size', 1, 100),\n",
    "    )\n",
    "\n",
    "    # Оцениваем модель с помощью кросс-валидации\n",
    "    score = cross_val_score(model, sentence_embeddings_train, y_train, cv=5, scoring='f1_macro').mean()\n",
    "\n",
    "    # Выводим логи\n",
    "    print(f'Trial {trial.number+1}: score = {score}')\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee85d52a-b3c5-438f-be5a-19e7027a90a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 38, 'weights': 'distance', 'metric': 'cosine', 'leaf_size': 51}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "580a5746-b841-43a4-a36d-1201eedba271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       286\n",
      "           1       1.00      1.00      1.00       169\n",
      "\n",
      "    accuracy                           1.00       455\n",
      "   macro avg       1.00      1.00      1.00       455\n",
      "weighted avg       1.00      1.00      1.00       455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       123\n",
      "           1       0.57      0.59      0.58        73\n",
      "\n",
      "    accuracy                           0.68       196\n",
      "   macro avg       0.66      0.66      0.66       196\n",
      "weighted avg       0.68      0.68      0.68       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = KNeighborsClassifier(**study.best_params)\n",
    "best_model.fit(sentence_embeddings_train, y_train)\n",
    "\n",
    "optimal_threshold = get_best_threshold(best_model, sentence_embeddings_train, y_train)\n",
    "y_train_pred = (best_model.predict_proba(sentence_embeddings_train)[:, 1] >= optimal_threshold).astype(int)\n",
    "y_test_pred = (best_model.predict_proba(sentence_embeddings_test)[:, 1] >= optimal_threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f018bde4-64fe-4ca9-8b05-b37e99c572e7",
   "metadata": {},
   "source": [
    "## 3.2. BERT + LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f0151-6207-40f3-aa30-2f78faada0a8",
   "metadata": {},
   "source": [
    "### 3.2.1. Пробная модель для первого вопроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4af43565-a53a-4acc-bdda-ca1df8d7976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d1ddc48-194d-47ab-af50-1387ab52a94b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: score = 0.6614812748806322\n",
      "Trial 2: score = 0.3859604571013967\n",
      "Trial 3: score = 0.6894930499652834\n",
      "Trial 4: score = 0.7018409577493976\n",
      "Trial 5: score = 0.7012338544717803\n",
      "Trial 6: score = 0.5982152105127241\n",
      "Trial 7: score = 0.6974121548570018\n",
      "Trial 8: score = 0.7017917265898284\n",
      "Trial 9: score = 0.6611744831215469\n",
      "Trial 10: score = 0.6653287132993304\n",
      "Trial 11: score = 0.6741382907308712\n",
      "Trial 12: score = 0.6647788978811398\n",
      "Trial 13: score = 0.6928075121626522\n",
      "Trial 14: score = 0.6700814312455255\n",
      "Trial 15: score = 0.69690173802947\n",
      "Trial 16: score = 0.6991421213372484\n",
      "Trial 17: score = 0.6828285147736338\n",
      "Trial 18: score = 0.664082626410262\n",
      "Trial 19: score = 0.3859604571013967\n",
      "Trial 20: score = 0.7134468911383731\n",
      "Trial 21: score = 0.6973285907707198\n",
      "Trial 22: score = 0.6955994968559998\n",
      "Trial 23: score = 0.716036750136338\n",
      "Trial 24: score = 0.7032073937831473\n",
      "Trial 25: score = 0.716036750136338\n",
      "Trial 26: score = 0.7140548217055015\n",
      "Trial 27: score = 0.6715489898511652\n",
      "Trial 28: score = 0.7108042613579262\n",
      "Trial 29: score = 0.69690173802947\n",
      "Trial 30: score = 0.6667784409370624\n",
      "Trial 31: score = 0.7020045626326112\n",
      "Trial 32: score = 0.7107935112411974\n",
      "Trial 33: score = 0.7072722810313116\n",
      "Trial 34: score = 0.6868497453589011\n",
      "Trial 35: score = 0.3859604571013967\n",
      "Trial 36: score = 0.7082637862940209\n",
      "Trial 37: score = 0.7049050557960355\n",
      "Trial 38: score = 0.6904514974863987\n",
      "Trial 39: score = 0.7083736166664989\n",
      "Trial 40: score = 0.6962887997193901\n",
      "Trial 41: score = 0.6847514106160212\n",
      "Trial 42: score = 0.7134468911383731\n",
      "Trial 43: score = 0.6909396848470173\n",
      "Trial 44: score = 0.7134786473268551\n",
      "Trial 45: score = 0.7018409577493976\n",
      "Trial 46: score = 0.6981662990388953\n",
      "Trial 47: score = 0.6840713531532923\n",
      "Trial 48: score = 0.716036750136338\n",
      "Trial 49: score = 0.6986877654933831\n",
      "Trial 50: score = 0.675004504042898\n",
      "Trial 51: score = 0.4614889999497488\n",
      "Trial 52: score = 0.716036750136338\n",
      "Trial 53: score = 0.7140059101288736\n",
      "Trial 54: score = 0.703900129597302\n",
      "Trial 55: score = 0.7052044687522316\n",
      "Trial 56: score = 0.6971232643607659\n",
      "Trial 57: score = 0.7072690148153333\n",
      "Trial 58: score = 0.700205252418961\n",
      "Trial 59: score = 0.6842022386973099\n",
      "Trial 60: score = 0.7017917265898284\n",
      "Trial 61: score = 0.696213833617582\n",
      "Trial 62: score = 0.7134468911383731\n",
      "Trial 63: score = 0.716036750136338\n",
      "Trial 64: score = 0.70377598414047\n",
      "Trial 65: score = 0.6979807469510451\n",
      "Trial 66: score = 0.7058317747074246\n",
      "Trial 67: score = 0.7072722810313116\n",
      "Trial 68: score = 0.6981662990388953\n",
      "Trial 69: score = 0.6614090917232609\n",
      "Trial 70: score = 0.6973667966311061\n",
      "Trial 71: score = 0.6613133153821344\n",
      "Trial 72: score = 0.7134786473268551\n",
      "Trial 73: score = 0.7140548217055015\n",
      "Trial 74: score = 0.6973285907707198\n",
      "Trial 75: score = 0.7087981607599315\n",
      "Trial 76: score = 0.6976894762896209\n",
      "Trial 77: score = 0.716036750136338\n",
      "Trial 78: score = 0.7087981607599315\n",
      "Trial 79: score = 0.6973787437609292\n",
      "Trial 80: score = 0.6992659128856205\n",
      "Trial 81: score = 0.7009523183593055\n",
      "Trial 82: score = 0.716036750136338\n",
      "Trial 83: score = 0.6955429463099086\n",
      "Trial 84: score = 0.6997082059636698\n",
      "Trial 85: score = 0.6980197740876799\n",
      "Trial 86: score = 0.716036750136338\n",
      "Trial 87: score = 0.7107935112411974\n",
      "Trial 88: score = 0.7040723749116912\n",
      "Trial 89: score = 0.699597576792704\n",
      "Trial 90: score = 0.7072722810313116\n",
      "Trial 91: score = 0.705255877104093\n",
      "Trial 92: score = 0.7140059101288736\n",
      "Trial 93: score = 0.7134786473268551\n",
      "Trial 94: score = 0.7063844858777071\n",
      "Trial 95: score = 0.6976329257435298\n",
      "Trial 96: score = 0.7108270049722191\n",
      "Trial 97: score = 0.6953466623398834\n",
      "Trial 98: score = 0.7029470546466345\n",
      "Trial 99: score = 0.70377598414047\n",
      "Trial 100: score = 0.6831748489084261\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    model = LogisticRegression(\n",
    "        C=trial.suggest_float('C', 1e-4, 1e4, log=True),\n",
    "        penalty=trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "        class_weight=trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "        solver='liblinear'\n",
    "    )\n",
    "\n",
    "    # Оцениваем модель с помощью кросс-валидации\n",
    "    score = cross_val_score(model, sentence_embeddings_train, y_train, cv=5, scoring='f1_macro').mean()\n",
    "\n",
    "    # Выводим логи\n",
    "    print(f'Trial {trial.number+1}: score = {score}')\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70cc0bba-3f65-4a6a-98f9-b75d3d8c775c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.09099591441633904, 'penalty': 'l2', 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "698699be-f59b-4c5e-8ca8-0028c2cd9e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       286\n",
      "           1       0.85      0.92      0.89       169\n",
      "\n",
      "    accuracy                           0.91       455\n",
      "   macro avg       0.90      0.91      0.91       455\n",
      "weighted avg       0.92      0.91      0.91       455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75       123\n",
      "           1       0.59      0.68      0.63        73\n",
      "\n",
      "    accuracy                           0.70       196\n",
      "   macro avg       0.69      0.70      0.69       196\n",
      "weighted avg       0.72      0.70      0.71       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = LogisticRegression(**study.best_params, solver='liblinear')\n",
    "best_model.fit(sentence_embeddings_train, y_train)\n",
    "\n",
    "optimal_threshold = get_best_threshold(best_model, sentence_embeddings_train, y_train)\n",
    "y_train_pred = (best_model.predict_proba(sentence_embeddings_train)[:, 1] >= optimal_threshold).astype(int)\n",
    "y_test_pred = (best_model.predict_proba(sentence_embeddings_test)[:, 1] >= optimal_threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aaac8f-3c6b-45b5-bbca-60f22012e477",
   "metadata": {},
   "source": [
    "## 3.3. BERT + Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d3b75-1413-446c-b41c-efa50929c27c",
   "metadata": {},
   "source": [
    "### 3.3.1. Пробная модель для первого вопроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61863378-4255-4876-8721-54cffe0bd3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa6ceeb5-4455-41ef-830f-c94790968026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.68      0.76       286\n",
      "           1       0.60      0.80      0.69       169\n",
      "\n",
      "    accuracy                           0.73       455\n",
      "   macro avg       0.73      0.74      0.72       455\n",
      "weighted avg       0.76      0.73      0.73       455\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74       123\n",
      "           1       0.57      0.75      0.65        73\n",
      "\n",
      "    accuracy                           0.70       196\n",
      "   macro avg       0.70      0.71      0.69       196\n",
      "weighted avg       0.73      0.70      0.70       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(sentence_embeddings_train, y_train)\n",
    "\n",
    "optimal_threshold = get_best_threshold(best_model, sentence_embeddings_train, y_train)\n",
    "y_train_pred = (model.predict_proba(sentence_embeddings_train)[:, 1] >= optimal_threshold).astype(int)\n",
    "y_test_pred = (model.predict_proba(sentence_embeddings_test)[:, 1] >= optimal_threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645419c5-7cbd-42ab-a112-745eb35ef7f5",
   "metadata": {},
   "source": [
    "Все три модели показывают худшее качество при классификации первого вопроса, чем при использовании TF-IDF + LogReg. Это может быть связано с тем, что BERT - довольно мощная и сложная модель и на небольшой выборке (которая имеется у нас) модели, использующие эмбеддинги BERT, могут легко переобучиться на тренировочный сет. BERT лучше применять в задачах с большим объемом данных, где он может получить больше информации для понимания контекста, и в следствии этого, лучше классифицировать тексты."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
